{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentiment-classification-with-keras.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMU4Biaay2v85eaoDX8Oc2M",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cs145442/nlp-projects-with-tf2/blob/master/sentiment_classification_with_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owi6ILm8eKki"
      },
      "source": [
        "## 0. Handling the dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-S8KuQIIjrB",
        "outputId": "582b130e-a81f-4823-b848-033a384c4706"
      },
      "source": [
        "# install all the dependencies here\n",
        "! pip install bert-for-tf2"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: bert-for-tf2 in /usr/local/lib/python3.6/dist-packages (0.14.7)\n",
            "Requirement already satisfied: params-flow>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from bert-for-tf2) (0.8.2)\n",
            "Requirement already satisfied: py-params>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from bert-for-tf2) (0.9.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (1.18.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vM9xOwpSp7NF"
      },
      "source": [
        "# import all the dependencies here\n",
        "try:\n",
        "    %tensorflow_version 2.x\n",
        "except Exception:\n",
        "    pass\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "import pandas as pd\n",
        "import bert\n",
        "\n",
        "import math\n",
        "import random\n",
        "import spacy"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcu-osRXxO3K"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import LSTM\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers import Bidirectional\n",
        "from keras.preprocessing import sequence\n",
        "from keras.layers import Dropout\n"
      ],
      "execution_count": 245,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QahPG6gO-cKK"
      },
      "source": [
        "## 1. Gathering the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpRFTW9kd7vf"
      },
      "source": [
        "### 1.1 Getting the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Na3cvAoVpdDZ",
        "outputId": "f5fc05e7-6fff-442f-8851-2ec44b036674"
      },
      "source": [
        "# add and unzip the dataset here\n",
        "! ls\n",
        "! wget http://nlp.stanford.edu/~socherr/stanfordSentimentTreebank.zip\n",
        "! unzip stanfordSentimentTreebank.zip"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__MACOSX  sample_data  stanfordSentimentTreebank  stanfordSentimentTreebank.zip\n",
            "--2020-11-23 09:07:38--  http://nlp.stanford.edu/~socherr/stanfordSentimentTreebank.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/~socherr/stanfordSentimentTreebank.zip [following]\n",
            "--2020-11-23 09:07:38--  https://nlp.stanford.edu/~socherr/stanfordSentimentTreebank.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6372817 (6.1M) [application/zip]\n",
            "Saving to: ‘stanfordSentimentTreebank.zip.1’\n",
            "\n",
            "stanfordSentimentTr 100%[===================>]   6.08M  7.91MB/s    in 0.8s    \n",
            "\n",
            "2020-11-23 09:07:39 (7.91 MB/s) - ‘stanfordSentimentTreebank.zip.1’ saved [6372817/6372817]\n",
            "\n",
            "Archive:  stanfordSentimentTreebank.zip\n",
            "replace stanfordSentimentTreebank/datasetSentences.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: stanfordSentimentTreebank/datasetSentences.txt  \n",
            "  inflating: __MACOSX/stanfordSentimentTreebank/._datasetSentences.txt  \n",
            "  inflating: stanfordSentimentTreebank/datasetSplit.txt  \n",
            "  inflating: __MACOSX/stanfordSentimentTreebank/._datasetSplit.txt  \n",
            "  inflating: stanfordSentimentTreebank/dictionary.txt  \n",
            "  inflating: __MACOSX/stanfordSentimentTreebank/._dictionary.txt  \n",
            "  inflating: stanfordSentimentTreebank/original_rt_snippets.txt  \n",
            "  inflating: __MACOSX/stanfordSentimentTreebank/._original_rt_snippets.txt  \n",
            "  inflating: stanfordSentimentTreebank/README.txt  \n",
            "  inflating: __MACOSX/stanfordSentimentTreebank/._README.txt  \n",
            "  inflating: stanfordSentimentTreebank/sentiment_labels.txt  \n",
            "  inflating: __MACOSX/stanfordSentimentTreebank/._sentiment_labels.txt  \n",
            "  inflating: stanfordSentimentTreebank/SOStr.txt  \n",
            "  inflating: stanfordSentimentTreebank/STree.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BHmfyEqqGm2",
        "outputId": "4d7ef59d-b69b-4c89-cc28-e434077c7858"
      },
      "source": [
        "! cat stanfordSentimentTreebank/README.txt"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Stanford Sentiment Treebank V1.0\n",
            "\n",
            "This is the dataset of the paper:\n",
            "\n",
            "Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank\n",
            "Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher Manning, Andrew Ng and Christopher Potts\n",
            "Conference on Empirical Methods in Natural Language Processing (EMNLP 2013)\n",
            "\n",
            "If you use this dataset in your research, please cite the above paper.\n",
            "\n",
            "@incollection{SocherEtAl2013:RNTN,\n",
            "title = {{Parsing With Compositional Vector Grammars}},\n",
            "author = {Richard Socher and Alex Perelygin and Jean Wu and Jason Chuang and Christopher Manning and Andrew Ng and Christopher Potts},\n",
            "booktitle = {{EMNLP}},\n",
            "year = {2013}\n",
            "}\n",
            "\n",
            "This file includes:\n",
            "1. original_rt_snippets.txt contains 10,605 processed snippets from the original pool of Rotten Tomatoes HTML files. Please note that some snippet may contain multiple sentences.\n",
            "\n",
            "2. dictionary.txt contains all phrases and their IDs, separated by a vertical line |\n",
            "\n",
            "3. sentiment_labels.txt contains all phrase ids and the corresponding sentiment labels, separated by a vertical line.\n",
            "Note that you can recover the 5 classes by mapping the positivity probability using the following cut-offs:\n",
            "[0, 0.2], (0.2, 0.4], (0.4, 0.6], (0.6, 0.8], (0.8, 1.0]\n",
            "for very negative, negative, neutral, positive, very positive, respectively.\n",
            "Please note that phrase ids and sentence ids are not the same.\n",
            "\n",
            "4. SOStr.txt and STree.txt encode the structure of the parse trees. \n",
            "STree encodes the trees in a parent pointer format. Each line corresponds to each sentence in the datasetSentences.txt file. The Matlab code of this paper will show you how to read this format if you are not familiar with it.\n",
            "\n",
            "5. datasetSentences.txt contains the sentence index, followed by the sentence string separated by a tab. These are the sentences of the train/dev/test sets.\n",
            "\n",
            "6. datasetSplit.txt contains the sentence index (corresponding to the index in datasetSentences.txt file) followed by the set label separated by a comma:\n",
            "\t1 = train\n",
            "\t2 = test\n",
            "\t3 = dev\n",
            "\n",
            "Please note that the datasetSentences.txt file has more sentences/lines than the original_rt_snippet.txt. \n",
            "Each row in the latter represents a snippet as shown on RT, whereas the former is each sub sentence as determined by the Stanford parser.\n",
            "\n",
            "For comparing research and training models, please use the provided train/dev/test splits.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LsMeNbfeVcX"
      },
      "source": [
        "### 1.2 Exploring the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSYcsx_dqLRE",
        "outputId": "87dc25c4-9cb5-4038-d978-5bda5f4a42bb"
      },
      "source": [
        "# take a peek at the dataset format\n",
        "! echo \"----- contents of the treebank -------------------\"\n",
        "! ls stanfordSentimentTreebank\n",
        "! echo \"----- first 5 lines of dictionary.txt ------------\"\n",
        "! tail -n 5 stanfordSentimentTreebank/dictionary.txt\n",
        "! echo \"----- first 5 lines of sentiment_labels.txt ------\"\n",
        "! tail -n 5 stanfordSentimentTreebank/sentiment_labels.txt"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----- contents of the treebank -------------------\n",
            "datasetSentences.txt  dictionary.txt\t\tREADME.txt\t      SOStr.txt\n",
            "datasetSplit.txt      original_rt_snippets.txt\tsentiment_labels.txt  STree.txt\n",
            "----- first 5 lines of dictionary.txt ------------\n",
            "zoning ordinances to protect your community from the dullest science fiction|220441\n",
            "zzzzzzzzz|179256\n",
            "élan|220442\n",
            "É|220443\n",
            "É um passatempo descompromissado|220444\n",
            "----- first 5 lines of sentiment_labels.txt ------\n",
            "239227|0.36111\n",
            "239228|0.38889\n",
            "239229|0.33333\n",
            "239230|0.88889\n",
            "239231|0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "z-Nle8lFwEJL",
        "outputId": "eabac7a3-037d-4828-ad66-b6ea8c1ca66f"
      },
      "source": [
        "# reading the dataset\n",
        "dataset_df = pd.read_csv('stanfordSentimentTreebank/dictionary.txt', sep='\\n')\n",
        "dataset_df.head()"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>!|0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>! '|22935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>! ''|18235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>! Alas|179257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>! Brilliant|22936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>! Brilliant !|40532</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   !|0\n",
              "0            ! '|22935\n",
              "1           ! ''|18235\n",
              "2        ! Alas|179257\n",
              "3    ! Brilliant|22936\n",
              "4  ! Brilliant !|40532"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnLK9Th-xevI"
      },
      "source": [
        "# formatting the dataframe for processing\n",
        "dataset_df['phrase_text'] = dataset_df['!|0'].apply(lambda x: x.split('|')[0])\n",
        "dataset_df['phrase_ids'] = dataset_df['!|0'].apply(lambda x: x.split('|')[1])\n",
        "dataset_df = dataset_df.drop('!|0', axis=1)"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "qcmS89OHxpMT",
        "outputId": "160ba2d4-b4ee-4988-e65d-b28ce5b36f70"
      },
      "source": [
        "# take a peek at the dataframe\n",
        "dataset_df.tail()"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>phrase_text</th>\n",
              "      <th>phrase_ids</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>239226</th>\n",
              "      <td>zoning ordinances to protect your community fr...</td>\n",
              "      <td>220441</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>239227</th>\n",
              "      <td>zzzzzzzzz</td>\n",
              "      <td>179256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>239228</th>\n",
              "      <td>élan</td>\n",
              "      <td>220442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>239229</th>\n",
              "      <td>É</td>\n",
              "      <td>220443</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>239230</th>\n",
              "      <td>É um passatempo descompromissado</td>\n",
              "      <td>220444</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              phrase_text phrase_ids\n",
              "239226  zoning ordinances to protect your community fr...     220441\n",
              "239227                                          zzzzzzzzz     179256\n",
              "239228                                               élan     220442\n",
              "239229                                                  É     220443\n",
              "239230                   É um passatempo descompromissado     220444"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "QgfEREDoycbU",
        "outputId": "7ec53371-f93c-41b8-aa61-aad442f4b2cf"
      },
      "source": [
        "# reading the sentiment data\n",
        "sentiment_df = pd.read_csv('stanfordSentimentTreebank/sentiment_labels.txt', sep='\\n')\n",
        "sentiment_df.head()"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>phrase ids|sentiment values</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0|0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1|0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2|0.44444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3|0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4|0.42708</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  phrase ids|sentiment values\n",
              "0                       0|0.5\n",
              "1                       1|0.5\n",
              "2                   2|0.44444\n",
              "3                       3|0.5\n",
              "4                   4|0.42708"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zamwPn3SefZ4"
      },
      "source": [
        "### 1.3 Formatting the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnxTPYOC4_FJ"
      },
      "source": [
        "# formatting the sentiment dataframe for processing\n",
        "sentiment_df['phrase_ids'] = sentiment_df['phrase ids|sentiment values'].apply(lambda x: x.split('|')[0])\n",
        "sentiment_df['sentiment_values'] = sentiment_df['phrase ids|sentiment values'].apply(lambda x: x.split('|')[1])\n",
        "sentiment_df = sentiment_df.drop('phrase ids|sentiment values', axis=1)"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "9Ag4UWqo5P-T",
        "outputId": "1b3bbdae-8080-46a1-cea8-35fc8c05480d"
      },
      "source": [
        "sentiment_df.head()"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>phrase_ids</th>\n",
              "      <th>sentiment_values</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.44444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.42708</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  phrase_ids sentiment_values\n",
              "0          0              0.5\n",
              "1          1              0.5\n",
              "2          2          0.44444\n",
              "3          3              0.5\n",
              "4          4          0.42708"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jr4PqXS45lqL",
        "outputId": "3c4720c4-cda8-4ab1-f4b9-b9bceee7cef3"
      },
      "source": [
        "# let's merge the phrases and sentiments\n",
        "dataset_sentiment_df = pd.merge(left=dataset_df, right=sentiment_df, how='inner', on='phrase_ids')\n",
        "# let's also validate the number of datapoints\n",
        "print(f\"dataset df shape: {dataset_df.shape}\")\n",
        "print(f\"sentiment df shape: {sentiment_df.shape}\")\n",
        "print(f\"dataset_sentiment df shape: {dataset_sentiment_df.shape}\")"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dataset df shape: (239231, 2)\n",
            "sentiment df shape: (239232, 2)\n",
            "dataset_sentiment df shape: (239231, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BBvdrf58jIS"
      },
      "source": [
        "*seems good. we missed one datapoint while merging, that's okay for now.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KryruhdYUr5y"
      },
      "source": [
        "def recover_sentiment_class(sentiment_value: float):\n",
        "  \"\"\"\n",
        "  recovering classes from sentiment_values\n",
        "  [very negative, negative, neutral, positive, very positive]\n",
        "  [0, 0.2], (0.2, 0.4], (0.4, 0.6], (0.6, 0.8], (0.8, 1.0]\n",
        "  [1, 2, 3, 4, 5]\n",
        "  respectively\n",
        "  :params:\n",
        "    sentiment_value: floating value of sentiment\n",
        "  \"\"\"\n",
        "  if sentiment_value <= 0.2:\n",
        "    return 1\n",
        "  elif sentiment_value <= 0.4:\n",
        "    return 2\n",
        "  elif sentiment_value <= 0.6:\n",
        "    return 3\n",
        "  elif sentiment_value <= 0.8:\n",
        "    return 4\n",
        "  else:\n",
        "    return 5"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_SD0R93U51s"
      },
      "source": [
        "dataset_sentiment_df['sentiment_class'] = dataset_sentiment_df['sentiment_values'].apply(\n",
        "    lambda x: recover_sentiment_class(float(x)))"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "CmU5J0sefMJz",
        "outputId": "22d66b87-82c2-4326-b360-738d45d27a03"
      },
      "source": [
        "dataset_sentiment_df.tail()"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>phrase_text</th>\n",
              "      <th>phrase_ids</th>\n",
              "      <th>sentiment_values</th>\n",
              "      <th>sentiment_class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>239226</th>\n",
              "      <td>zoning ordinances to protect your community fr...</td>\n",
              "      <td>220441</td>\n",
              "      <td>0.13889</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>239227</th>\n",
              "      <td>zzzzzzzzz</td>\n",
              "      <td>179256</td>\n",
              "      <td>0.19444</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>239228</th>\n",
              "      <td>élan</td>\n",
              "      <td>220442</td>\n",
              "      <td>0.51389</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>239229</th>\n",
              "      <td>É</td>\n",
              "      <td>220443</td>\n",
              "      <td>0.5</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>239230</th>\n",
              "      <td>É um passatempo descompromissado</td>\n",
              "      <td>220444</td>\n",
              "      <td>0.5</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              phrase_text  ... sentiment_class\n",
              "239226  zoning ordinances to protect your community fr...  ...               1\n",
              "239227                                          zzzzzzzzz  ...               1\n",
              "239228                                               élan  ...               3\n",
              "239229                                                  É  ...               3\n",
              "239230                   É um passatempo descompromissado  ...               3\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QoMMQF2c-mK2"
      },
      "source": [
        "## 2. Generate Input Features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-ebOUBRdkFo"
      },
      "source": [
        "### 2.1 Generating the word vectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7ZPxL5fxFXG"
      },
      "source": [
        "### 2.1.a With Keras Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJSHxvGExJ9f"
      },
      "source": [
        "keras_tokenizer = Tokenizer(num_words=1500, split=' ')\n",
        "keras_tokenizer.fit_on_texts(dataset_sentiment_df['phrase_text'].values)\n",
        "sequenced_dataset = keras_tokenizer.texts_to_sequences(dataset_sentiment_df['phrase_text'])\n",
        "sequenced_dataset = pad_sequences(sequenced_dataset)"
      ],
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjuTl-aMxBLi"
      },
      "source": [
        "### 2.1.b With Bert Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Op-SSToHIW2"
      },
      "source": [
        "# let's setup the tokenizer\n",
        "BertTokenizer = bert.bert_tokenization.FullTokenizer\n",
        "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\",\n",
        "                            trainable=False)\n",
        "# define the vocab and tokenizer from the bert_layer here\n",
        "vocabulary_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "to_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "tokenizer = BertTokenizer(vocabulary_file, to_lower_case)"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bQ-cgqcI3is"
      },
      "source": [
        "# simple function to encode the sentence\n",
        "def encode_sentence(sent):\n",
        "    return tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sent))"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--qgucgx7njO"
      },
      "source": [
        "encoded_phrases = dataset_sentiment_df['phrase_text'].apply(lambda x: encode_sentence(x))"
      ],
      "execution_count": 223,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdiALOlv8U5_"
      },
      "source": [
        "encoded_phrases = pad_sequences(encoded_phrases)"
      ],
      "execution_count": 225,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e64qjpT6IM5q"
      },
      "source": [
        "*we're using bert layer for tokenization only!*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7u6v67jIQ5Z",
        "outputId": "a3e626d8-47a8-4324-c5d7-e8cc7a80f5ea"
      },
      "source": [
        "tokenizer.tokenize(\"don't be so judgemental\")"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['don', \"'\", 't', 'be', 'so', 'judgement', '##al']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOTT55Tkd011"
      },
      "source": [
        "### 2.2 Generating the POS Tags\n",
        "*Indicates the part-of-speech tag of the word*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmJ2lxqNqu81"
      },
      "source": [
        "# load the spacy model\n",
        "spacy_nlp_model = spacy.load(\"en_core_web_sm\")"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "id": "CvkECt_LnREz",
        "outputId": "4af64a6c-2142-4be6-8130-9455f93dc547"
      },
      "source": [
        "# let's create the spacy token objects of all the sequences\n",
        "list_of_phrases_spacy_docs = [spacy_nlp_model(phrase) for phrase in list_of_phrases]"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-131-ad5f1e1ea4d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# let's create the spacy token objects of all the sequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlist_of_phrases_spacy_docs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mspacy_nlp_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphrase\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mphrase\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist_of_phrases\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-131-ad5f1e1ea4d6>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# let's create the spacy token objects of all the sequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlist_of_phrases_spacy_docs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mspacy_nlp_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphrase\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mphrase\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist_of_phrases\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/spacy/language.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[1;32m    437\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__call__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE003\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcomponent_cfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE005\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mnn_parser.pyx\u001b[0m in \u001b[0;36mspacy.syntax.nn_parser.Parser.__call__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mnn_parser.pyx\u001b[0m in \u001b[0;36mspacy.syntax.nn_parser.Parser.predict\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mnn_parser.pyx\u001b[0m in \u001b[0;36mspacy.syntax.nn_parser.Parser.greedy_parse\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/thinc/neural/_classes/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0mMust\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0mexpected\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \"\"\"\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/thinc/neural/_classes/model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m_parser_model.pyx\u001b[0m in \u001b[0;36mspacy.syntax._parser_model.ParserModel.begin_update\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m_parser_model.pyx\u001b[0m in \u001b[0;36mspacy.syntax._parser_model.ParserStepModel.__init__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/thinc/neural/_classes/feed_forward.py\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(self, X, drop)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/thinc/api.py\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(seqs_in, drop)\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseqs_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mseq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseqs_in\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbp_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseqs_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbp_layer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/thinc/neural/_classes/feed_forward.py\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(self, X, drop)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/thinc/neural/_classes/resnet.py\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(self, X, drop)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbp_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/thinc/neural/_classes/feed_forward.py\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(self, X, drop)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/thinc/neural/_classes/layernorm.py\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(self, X, drop)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchild\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackprop_child\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mbackprop_child\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/thinc/neural/_classes/maxout.py\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(self, X__bi, drop)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdrop\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mdrop\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_factor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0moutput__boc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgemm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX__bi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrans2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0moutput__boc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnO\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnP\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0moutput__boc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput__boc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput__boc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kH6vWCumd5BC"
      },
      "source": [
        "def get_pos_tags(doc: spacy.tokens.doc.Doc):\n",
        "  \"\"\"\n",
        "  returns a list of token's POS Tags\n",
        "  \"\"\"\n",
        "  # generator of pos tags for the sequence or word\n",
        "  tags = []\n",
        "  for token in doc:\n",
        "    tags.append(token.pos_)\n",
        "  return tags\n",
        "\n",
        "\n",
        "dict_of_pos_tags = {}\n",
        "def get_pos_tag2id(pos_tag: str):\n",
        "  \"\"\"\n",
        "  returns the id for the POS Tag from the universal dict of POS Tags\n",
        "  \"\"\"\n",
        "  id = dict_of_pos_tags.get(pos_tag, None)\n",
        "  if id is None:\n",
        "    # i.e, POS Tag is not in the dict\n",
        "    # Add the new POS Tag to the dict\n",
        "    new_id = len(dict_of_pos_tags) + 1\n",
        "    dict_of_pos_tags[pos_tag] = new_id\n",
        "    return new_id\n",
        "  else:\n",
        "    return id\n",
        "\n",
        "\n",
        "def get_pos_tag_ids(doc: spacy.tokens.doc.Doc):\n",
        "  \"\"\"\n",
        "  returns a list of token's POS Tags ID's\n",
        "  \"\"\"\n",
        "  tag_ids = []\n",
        "  for token in doc:\n",
        "    tag_ids.append(get_pos_tag2id(token.pos_))\n",
        "  return tag_ids"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jPoe6hmgkbx"
      },
      "source": [
        "list_of_phrases_pos_tags = [get_pos_tags(phrase) for phrase in list_of_phrases_spacy_docs]\n",
        "list_of_phrases_pos_tag_ids = [get_pos_tag_ids(phrase) for phrase in list_of_phrases_spacy_docs]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85Jlv6cAjIYU"
      },
      "source": [
        "### 2.3 Generate the word shape\n",
        "*Indicates whether a word start with a captial letter?*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5WAdjskjVp7"
      },
      "source": [
        "def get_word_shape(doc: spacy.tokens.doc.Doc):\n",
        "  \"\"\"\n",
        "  returns a list of token's shape\n",
        "  \"\"\"\n",
        "  shapes = []\n",
        "  for token in doc:\n",
        "    shapes.append(token.shape_)\n",
        "  return shapes\n",
        "\n",
        "def get_init_word_case_match(doc: spacy.tokens.doc.Doc):\n",
        "  \"\"\"\n",
        "  returns a list of token's initial case match indicator\n",
        "  indicators: 1 if the token begins with an UPPERCASE letter\n",
        "  indicators: 2 if the token begins with an lowercase letter\n",
        "  \"\"\"\n",
        "  init_word_case_match = []\n",
        "  for token in doc:\n",
        "    init_word_case_match.append(1 if token.text.istitle() else 2)\n",
        "  return init_word_case_match"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cnn9a2djvRv"
      },
      "source": [
        "# list_of_phrases_word_shape\n",
        "list_of_phrases_word_shape = [get_word_shape(phrase) for phrase in list_of_phrases_spacy_docs]\n",
        "list_of_phrases_init_word_case_match = [get_init_word_case_match(phrase) for phrase in list_of_phrases_spacy_docs]"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIdn0S901pQn"
      },
      "source": [
        "### 2.4 Generate the lemmatized word sequence\n",
        "*Indicates whether a word end with an “ing” or with “ly” or neither?*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhuC-xGh18Cm"
      },
      "source": [
        "def get_word_lemma(doc: spacy.tokens.doc.Doc):\n",
        "  \"\"\"\n",
        "  returns a list of token's lemma\n",
        "  \"\"\"\n",
        "  lemmas = []\n",
        "  for token in doc:\n",
        "    lemmas.append(token.lemma_)\n",
        "  return lemmas\n",
        "\n",
        "def get_word_lemma_match(doc: spacy.tokens.doc.Doc):\n",
        "  \"\"\"\n",
        "  returns a list of token's lemma match indicator\n",
        "  indicators: 1 if there's a match of token with it's lemma\n",
        "  indicators: 2 if there's not a match of token with it's lemma\n",
        "  \"\"\"\n",
        "  lemma_match = []\n",
        "  for token in doc:\n",
        "    if token.text == token.lemma_:\n",
        "      lemma_match.append(1)\n",
        "    else:\n",
        "      lemma_match.append(2)\n",
        "  return lemma_match"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPZXOBas232c"
      },
      "source": [
        "list_of_phrases_lemma = [get_word_lemma(phrase) for phrase in list_of_phrases_spacy_docs]\n",
        "list_of_phrases_lemma_match = [get_word_lemma_match(phrase) for phrase in list_of_phrases_spacy_docs]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVB_bdXWUCGz"
      },
      "source": [
        "y = dataset_sentiment_df['sentiment_class']\n",
        "\n",
        "list_of_pharses_with_length = [[phrase, y[i], len(phrase)]\n",
        "                 for i, phrase in enumerate(encoded_phrases)]\n",
        "\n",
        "random.shuffle(list_of_pharses_with_length)\n",
        "list_of_pharses_with_length.sort(key=lambda x: x[2])\n",
        "\n",
        "sorted_phrases_sentiments = [(phrase_with_length[0], phrase_with_length[1]) for phrase_with_length in list_of_pharses_with_length]"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmcnznIDsZ4q"
      },
      "source": [
        "## 3. Sentiment Analysis \n",
        "#### without multiple input features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Nn4kTjTyCD3"
      },
      "source": [
        "### 3.1 Sentiment Analysis with Keras Tokenizer using LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6UKOvoSChPG"
      },
      "source": [
        "### 3.1.a \n",
        "\n",
        "loss: sparse_categorical_crossentropy\n",
        "\n",
        "optimizer: adam\n",
        "\n",
        "metrics: accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OibF-QlEyMbD",
        "outputId": "29ef2dd6-ba7d-4d25-aaaf-386691e0af58"
      },
      "source": [
        "vocab_size = 1500\n",
        "embed_dim = 128\n",
        "lstm_out = 196\n",
        "input_length = 45\n",
        "\n",
        "simple_model = Sequential()\n",
        "simple_model.add(Embedding(vocab_size, embed_dim,input_length=input_length))\n",
        "simple_model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
        "simple_model.add(Dense(5,activation='softmax'))\n",
        "simple_model.compile(loss = 'sparse_categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])"
      ],
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_13 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_13 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZ7kXTOAy7XJ",
        "outputId": "e462762e-24fb-477e-8431-feb039a8b349"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    sequenced_dataset,\n",
        "    dataset_sentiment_df['sentiment_class'],\n",
        "    test_size = 0.40,\n",
        "    random_state = 42\n",
        "    )\n",
        "\n",
        "simple_model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    validation_data = (X_test,y_test),\n",
        "    epochs = 1,\n",
        "    batch_size=64\n",
        "    )"
      ],
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2243/2243 [==============================] - 440s 196ms/step - loss: nan - accuracy: 6.2701e-05 - val_loss: nan - val_accuracy: 0.0000e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f55f2132e10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 218
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Ld8ErvRzwP0",
        "outputId": "2906cb59-15bc-4baf-d7eb-63b6ed43d714"
      },
      "source": [
        "simple_model.evaluate(X_test,y_test)"
      ],
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2991/2991 [==============================] - 43s 14ms/step - loss: nan - accuracy: 0.0000e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[nan, 0.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 219
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7abLT2IOCvP9"
      },
      "source": [
        "### 3.1.b\n",
        "\n",
        "loss: sparse_categorical_crossentropy\n",
        "\n",
        "optimizer: adam\n",
        "\n",
        "metrics: sparse_categorical_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCOtikq2BrxE"
      },
      "source": [
        "vocab_size = 1500\n",
        "embed_dim = 128\n",
        "lstm_out = 196\n",
        "input_length = 45\n",
        "\n",
        "simple_model = Sequential()\n",
        "simple_model.add(Embedding(vocab_size, embed_dim,input_length=input_length))\n",
        "simple_model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0))\n",
        "simple_model.add(Dense(5,activation='softmax'))\n",
        "simple_model.compile(loss = 'sparse_categorical_crossentropy', optimizer='adam',metrics = ['sparse_categorical_accuracy'])"
      ],
      "execution_count": 241,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7_JTBppC-qZ",
        "outputId": "3f6a49ae-79a0-4e43-b275-aac581a30d2c"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    sequenced_dataset,\n",
        "    dataset_sentiment_df['sentiment_class'],\n",
        "    test_size = 0.40,\n",
        "    random_state = 42\n",
        "    )\n",
        "\n",
        "simple_model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    validation_data = (X_test,y_test),\n",
        "    epochs = 1,\n",
        "    batch_size=32\n",
        "    )"
      ],
      "execution_count": 242,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4486/4486 [==============================] - 48s 11ms/step - loss: nan - sparse_categorical_accuracy: 7.6635e-05 - val_loss: nan - val_sparse_categorical_accuracy: 0.0000e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f55f0ef37b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 242
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2AL6zRtqDF7A",
        "outputId": "076cf520-0128-4ec8-8871-1dabf9714e47"
      },
      "source": [
        "simple_model.evaluate(X_test,y_test)"
      ],
      "execution_count": 243,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2991/2991 [==============================] - 10s 3ms/step - loss: nan - sparse_categorical_accuracy: 0.0000e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[nan, 0.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 243
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLFJxpE_yIJb"
      },
      "source": [
        "### 3.2 Sentiment Analysis with Bert Tokenizer using LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICF0yA6T-JZu"
      },
      "source": [
        "#### 3.2.a \n",
        "\n",
        "loss: sparse_categorical_crossentropy\n",
        "\n",
        "optimizer: adam\n",
        "\n",
        "metrics: accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ah3rtCCx5RU-"
      },
      "source": [
        "# Defining all the hyperparameters\n",
        "vocab_size = len(tokenizer.vocab)\n",
        "embed_dim = 128\n",
        "lstm_out = 196\n",
        "input_length = 64\n",
        "\n",
        "simple_model_with_bert = Sequential()\n",
        "simple_model_with_bert.add(Embedding(vocab_size, embed_dim,input_length=input_length))\n",
        "simple_model_with_bert.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0))\n",
        "simple_model_with_bert.add(Dense(5,activation='softmax'))\n",
        "simple_model_with_bert.compile(loss = 'sparse_categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])"
      ],
      "execution_count": 232,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gh94Y6Hr6hdw",
        "outputId": "4c143054-8154-4020-cfae-01e1a32aeb04"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    encoded_phrases,\n",
        "    dataset_sentiment_df['sentiment_class'],\n",
        "    test_size = 0.40,\n",
        "    random_state = 42\n",
        "    )\n",
        "\n",
        "simple_model_with_bert.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    validation_data = (X_test,y_test),\n",
        "    epochs = 1,\n",
        "    batch_size=32\n",
        "    )"
      ],
      "execution_count": 233,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4486/4486 [==============================] - 197s 44ms/step - loss: nan - accuracy: 6.2701e-05 - val_loss: nan - val_accuracy: 0.0000e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f568c88e748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 233
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9u1KsuTv6sUL"
      },
      "source": [
        "simple_model_with_bert.evaluate(X_test,y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGqAJQGC-WKy"
      },
      "source": [
        "### 3.2.b \n",
        "\n",
        "loss: sparse_categorical_crossentropy\n",
        "\n",
        "optimizer: adam\n",
        "\n",
        "metrics: sparse_categorical_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8smr0TH-C0E"
      },
      "source": [
        "# Defining all the hyperparameters\n",
        "vocab_size = len(tokenizer.vocab)\n",
        "embed_dim = 128\n",
        "lstm_out = 196\n",
        "input_length = 64\n",
        "\n",
        "simple_model_with_bert = Sequential()\n",
        "simple_model_with_bert.add(Embedding(vocab_size, embed_dim,input_length=input_length))\n",
        "simple_model_with_bert.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0))\n",
        "simple_model_with_bert.add(Dense(5,activation='softmax'))\n",
        "simple_model_with_bert.compile(loss = 'sparse_categorical_crossentropy', optimizer='adam',metrics = ['sparse_categorical_accuracy'])"
      ],
      "execution_count": 234,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiXNmVsf-bXv",
        "outputId": "1b6824a3-f346-4f35-b62f-9c6b479cae76"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    encoded_phrases,\n",
        "    dataset_sentiment_df['sentiment_class'],\n",
        "    test_size = 0.40,\n",
        "    random_state = 42\n",
        "    )\n",
        "\n",
        "simple_model_with_bert.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    validation_data = (X_test,y_test),\n",
        "    epochs = 1,\n",
        "    batch_size=32\n",
        "    )"
      ],
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4486/4486 [==============================] - 198s 44ms/step - loss: nan - sparse_categorical_accuracy: 8.3602e-05 - val_loss: nan - val_sparse_categorical_accuracy: 0.0000e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f55f17b6fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 235
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWTkxCBF_SMr",
        "outputId": "4cd7f7d1-685d-4caa-da7d-bb62f9cfce6b"
      },
      "source": [
        "simple_model_with_bert.evaluate(X_test, y_test)"
      ],
      "execution_count": 236,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2991/2991 [==============================] - 13s 4ms/step - loss: nan - sparse_categorical_accuracy: 0.0000e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[nan, 0.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 236
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0y9BHAgTECKO"
      },
      "source": [
        "### Experimental\n",
        "\n",
        "Using Tensorflow dataset from_generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66DQplvKe2mm"
      },
      "source": [
        "encoded_phrases_with_len = [[encoded_phrase, y[i], len(encoded_phrase)]\n",
        "                 for i, encoded_phrase in enumerate(encoded_phrases)]\n",
        "random.shuffle(encoded_phrases_with_len)\n",
        "encoded_phrases_with_len.sort(key=lambda x: x[2])\n",
        "sorted_encoded_phrases_with_sentiment = [(encoded_phrase_with_len[0], encoded_phrase_with_len[1]) for encoded_phrase_with_len in encoded_phrases_with_len]\n",
        "\n",
        "processed_dataset = tf.data.Dataset.from_generator(lambda: sorted_encoded_phrases_with_sentiment, output_types=(tf.int32, tf.int32))\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "batched_dataset = processed_dataset.padded_batch(BATCH_SIZE, padded_shapes=((None, ), ()))\n",
        "\n",
        "TOTAL_BATCHES = math.ceil(len(sorted_encoded_phrases_with_sentiment) / BATCH_SIZE)\n",
        "TEST_BATCHES = TOTAL_BATCHES // 10\n",
        "batched_dataset.shuffle(TOTAL_BATCHES)\n",
        "test_data = batched_dataset.take(TEST_BATCHES)\n",
        "train_data = batched_dataset.skip(TEST_BATCHES)"
      ],
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gugXL-Wg9mG"
      },
      "source": [
        "class PlainSentimentLSTM(tf.keras.Model):\n",
        "  def __init__(self,\n",
        "               vocabulary_size,\n",
        "               lstm_out=200,\n",
        "               embedding_dimensions=128,\n",
        "               dropout_rate=0.2,\n",
        "               recurrent_dropout=0,\n",
        "               sentiment_classes=5,\n",
        "               training=False,\n",
        "               name=\"PlainSentimentLSTM\"\n",
        "               ):\n",
        "        super(PlainSentimentLSTM, self).__init__(name=name)\n",
        "        \n",
        "        self.embedding = layers.Embedding(\n",
        "            vocabulary_size,\n",
        "            embedding_dimensions,\n",
        "            input_length=512\n",
        "            )\n",
        "        self.lstm_layer = layers.LSTM(\n",
        "            lstm_out,\n",
        "            dropout=dropout_rate,\n",
        "            recurrent_dropout=recurrent_dropout\n",
        "            )\n",
        "        self.last_dense = layers.Dense(\n",
        "            units=sentiment_classes,\n",
        "            activation=\"softmax\"\n",
        "            )\n",
        "        \n",
        "  def call(self, inputs, training):\n",
        "    l = self.embedding(inputs)\n",
        "    concatenated = self.lstm_layer(l, training)\n",
        "    model_output = self.last_dense(concatenated)\n",
        "    return model_output\n",
        "\n",
        "sentiment_model = PlainSentimentLSTM(\n",
        "    vocabulary_size=VOCAB_LENGTH\n",
        "    )\n",
        "\n",
        "sentiment_model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                       optimizer=\"adam\",\n",
        "                       metrics=[\"sparse_categorical_accuracy\"])"
      ],
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTNVBNN9BIAd"
      },
      "source": [
        "### Experimental (Without LSTM)\n",
        "\n",
        "Tri-Gram Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9TCeq2em5gO"
      },
      "source": [
        "class MCTC_MODEL(tf.keras.Model):\n",
        "    \n",
        "    def __init__(self,\n",
        "                 vocabulary_size,\n",
        "                 embedding_dimensions=128,\n",
        "                 cnn_filters=50,\n",
        "                 dnn_units=512,\n",
        "                 model_output_classes=2,\n",
        "                 dropout_rate=0.1,\n",
        "                 training=False,\n",
        "                 name=\"mctc_model\"):\n",
        "        super(MCTC_MODEL, self).__init__(name=name)\n",
        "        \n",
        "        self.embedding = layers.Embedding(vocabulary_size,\n",
        "                                          embedding_dimensions)\n",
        "        self.cnn_layer1 = layers.Conv1D(filters=cnn_filters,\n",
        "                                        kernel_size=2,\n",
        "                                        padding=\"valid\",\n",
        "                                        activation=\"relu\")\n",
        "        self.cnn_layer2 = layers.Conv1D(filters=cnn_filters,\n",
        "                                        kernel_size=3,\n",
        "                                        padding=\"valid\",\n",
        "                                        activation=\"relu\")\n",
        "        self.cnn_layer3 = layers.Conv1D(filters=cnn_filters,\n",
        "                                        kernel_size=4,\n",
        "                                        padding=\"valid\",\n",
        "                                        activation=\"relu\")\n",
        "        self.pool = layers.GlobalMaxPool1D()\n",
        "        \n",
        "        self.dense_1 = layers.Dense(units=dnn_units, activation=\"relu\")\n",
        "        self.dropout = layers.Dropout(rate=dropout_rate)\n",
        "        if model_output_classes == 2:\n",
        "            self.last_dense = layers.Dense(units=1,\n",
        "                                           activation=\"sigmoid\")\n",
        "        else:\n",
        "            self.last_dense = layers.Dense(units=model_output_classes,\n",
        "                                           activation=\"softmax\")\n",
        "    \n",
        "    def call(self, inputs, training):\n",
        "        l = self.embedding(inputs)\n",
        "        l_1 = self.cnn_layer1(l) \n",
        "        l_1 = self.pool(l_1) \n",
        "        l_2 = self.cnn_layer2(l) \n",
        "        l_2 = self.pool(l_2)\n",
        "        l_3 = self.cnn_layer3(l)\n",
        "        l_3 = self.pool(l_3) \n",
        "        \n",
        "        concatenated = tf.concat([l_1, l_2, l_3], axis=-1) # (batch_size, 3 * cnn_filters)\n",
        "        concatenated = self.dense_1(concatenated)\n",
        "        concatenated = self.dropout(concatenated, training)\n",
        "        model_output = self.last_dense(concatenated)\n",
        "        \n",
        "        return model_output"
      ],
      "execution_count": 237,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNUxhOF9nhzn"
      },
      "source": [
        "VOCAB_LENGTH = len(tokenizer.vocab)\n",
        "EMB_DIM = 200\n",
        "CNN_FILTERS = 100\n",
        "DNN_UNITS = 256\n",
        "OUTPUT_CLASSES = 5\n",
        "DROPOUT_RATE = 0.2\n",
        "\n",
        "\n",
        "text_model = MCTC_MODEL(vocabulary_size=VOCAB_LENGTH,\n",
        "                        embedding_dimensions=EMB_DIM,\n",
        "                        cnn_filters=CNN_FILTERS,\n",
        "                        dnn_units=DNN_UNITS,\n",
        "                        model_output_classes=OUTPUT_CLASSES,\n",
        "                        dropout_rate=DROPOUT_RATE)\n",
        "\n",
        "text_model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                       optimizer=\"adam\",\n",
        "                       metrics=[\"sparse_categorical_accuracy\"])"
      ],
      "execution_count": 238,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZ0pT4ehnpqP",
        "outputId": "ce94bb59-f32d-4a16-cd83-bf0f018ed53f"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    encoded_phrases,\n",
        "    dataset_sentiment_df['sentiment_class'],\n",
        "    test_size = 0.40,\n",
        "    random_state = 42\n",
        "    )\n",
        "\n",
        "\n",
        "text_model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    validation_data = (X_test,y_test),\n",
        "    epochs = 1,\n",
        "    batch_size=32\n",
        "    )"
      ],
      "execution_count": 239,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4486/4486 [==============================] - 260s 58ms/step - loss: nan - sparse_categorical_accuracy: 4.8768e-05 - val_loss: nan - val_sparse_categorical_accuracy: 0.0000e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f55f1200b70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 239
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wk4Gj92KBW-b",
        "outputId": "d390540a-e1d8-427c-ca7f-6fffae807984"
      },
      "source": [
        "text_model.evaluate(X_test, y_test)"
      ],
      "execution_count": 240,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2991/2991 [==============================] - 9s 3ms/step - loss: nan - sparse_categorical_accuracy: 0.0000e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[nan, 0.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 240
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYrinY9IBZqZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pc_yBrsu3NXz"
      },
      "source": [
        "### Experimental: Input features"
      ]
    }
  ]
}